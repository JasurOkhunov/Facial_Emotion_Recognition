{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "path = \"Users/masih/desktop/FER_2013\" # path to all images\n",
    "\n",
    "angry_images = glob.glob(path + 'train/angry/*', recursive=True)\n",
    "fear_images = glob.glob(path + 'train/fear/*', recursive=True)\n",
    "happy_images = glob.glob(path + 'train/happy/*', recursive=True)\n",
    "neutral_images = glob.glob(path + 'train/neutral/*', recursive=True)\n",
    "surprise_images = glob.glob(path + 'train/surprise/*', recursive=True)\n",
    "sad_images = glob.glob(path + 'train/sad/*', recursive=True)\n",
    "\n",
    "train_images = angry_images + fear_images + happy_images + neutral_images + surprise_images + sad_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angry_images = glob.glob(path + 'test/angry/*', recursive=True)\n",
    "fear_images = glob.glob(path + 'test/fear/*', recursive=True)\n",
    "happy_images = glob.glob(path + 'test/happy/*', recursive=True)\n",
    "neutral_images = glob.glob(path + 'test/neutral/*', recursive=True)\n",
    "surprise_images = glob.glob(path + 'test/surprise/*', recursive=True)\n",
    "sad_images = glob.glob(path + 'test/sad/*', recursive=True)\n",
    "\n",
    "test_images = angry_images + fear_images + happy_images + neutral_images + surprise_images + sad_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train images:  19012\n",
      "Number of val images:  3803\n",
      "Number of test images:  5931\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.shuffle(train_images)\n",
    "np.random.shuffle(test_images)\n",
    "\n",
    "# Using 80% of development data for training and 20% for validation\n",
    "train_images = train_images[:int(len(train_images)*0.8)]\n",
    "val_images = train_images[int(len(train_images)*0.8):]\n",
    "\n",
    "print(\"Number of train images: \", len(train_images))\n",
    "print(\"Number of val images: \", len(val_images))\n",
    "print(\"Number of test images: \", len(test_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "\n",
    "def preprocess(image_paths, cat, target_size, train = False, label_encoder = None):\n",
    "    images, labels = [], []\n",
    "\n",
    "    # Opening all images in image_paths, resizing them, saving as np arrays\n",
    "    for path in image_paths:\n",
    "        img = Image.open(path).convert('RGB')\n",
    "        img = img.resize(target_size)\n",
    "        img_array = np.array(img) / 255.0  \n",
    "        images.append(img_array)\n",
    "\n",
    "    # Saving all labels based on path name in list labels \n",
    "    for path in image_paths:\n",
    "        label = os.path.basename(os.path.dirname(path))\n",
    "        labels.append(label)\n",
    "        \n",
    "    # Fitting/ Creating a label encoder \n",
    "    if train:\n",
    "        label_encoder = LabelEncoder()\n",
    "        encoded_labels = label_encoder.fit_transform(labels)\n",
    "    else:\n",
    "        encoded_labels = label_encoder.transform(labels)\n",
    "\n",
    "    # Fitting a One-Hot-Encoding to the encoded labels\n",
    "    onehot_encoder = OneHotEncoder(sparse=False)\n",
    "    encoded_labels = encoded_labels.reshape(len(encoded_labels), 1)\n",
    "    onehot_labels = onehot_encoder.fit_transform(encoded_labels)\n",
    "\n",
    "    images = np.array([img.reshape(target_size[0], target_size[1], 3) for img in images])\n",
    "    labels = np.array(onehot_labels)\n",
    "    \n",
    "    save_path = \"Users/masih/desktop/FER_CNN/Data\" # path to saved NumPy arrays\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    \n",
    "    # Saving the numpy arrays\n",
    "    np.save(os.path.join(save_path, 'X_' + cat + '.npy'), images)\n",
    "    np.save(os.path.join(save_path, 'y_' + cat + '.npy'), labels)\n",
    "\n",
    "    return label_encoder\n",
    "\n",
    "\n",
    "target_size = (224, 224)\n",
    "\n",
    "# The Label Encoder is saved from training and then applied to validation and test data\n",
    "label_encoder = preprocess(train_images, 'train', target_size, train=True)\n",
    "preprocess(validation_images, 'validation',target_size, label_encoder=label_encoder)\n",
    "preprocess(test_images, 'test', target_size, label_encoder=label_encoder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "f1062708a37074d70712b695aadee582e0b0b9f95f45576b5521424137d05fec"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
